{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "609c01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4], dtype=torch.int32)\n",
      "tensor([[[0.4958, 0.4058, 0.1182, 0.5791],\n",
      "         [0.0496, 0.2688, 0.8308, 0.2501],\n",
      "         [0.8285, 0.4376, 0.9953, 0.0588],\n",
      "         [0.2969, 0.7258, 0.6915, 0.2288]],\n",
      "\n",
      "        [[0.1320, 0.4623, 0.4608, 0.3693],\n",
      "         [0.0656, 0.2772, 0.3697, 0.7058],\n",
      "         [0.5381, 0.8132, 0.0411, 0.1388],\n",
      "         [0.9907, 0.0395, 0.6499, 0.4306]]])\n",
      "tensor([[[0.4958, 0.4058,   -inf,   -inf],\n",
      "         [0.0496, 0.2688,   -inf,   -inf],\n",
      "         [  -inf,   -inf,   -inf,   -inf],\n",
      "         [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[0.1320, 0.4623, 0.4608, 0.3693],\n",
      "         [0.0656, 0.2772, 0.3697, 0.7058],\n",
      "         [0.5381, 0.8132, 0.0411, 0.1388],\n",
      "         [0.9907, 0.0395, 0.6499, 0.4306]]])\n",
      "tensor([[[0.5225, 0.4775, 0.0000, 0.0000],\n",
      "         [0.4454, 0.5546, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.1981, 0.2756, 0.2752, 0.2511],\n",
      "         [0.1822, 0.2252, 0.2470, 0.3456],\n",
      "         [0.2781, 0.3662, 0.1692, 0.1865],\n",
      "         [0.3747, 0.1447, 0.2665, 0.2140]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# wordembedding 以序列建模为例\n",
    "batch_size = 2\n",
    "\n",
    "# 单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "\n",
    "# 序列的最大长度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)  # 源序列长度\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)  # 目标序列长度\n",
    "\n",
    "# 以单词索引构成的源句子和目标句子，构建batch，并且做了padding，默认值为0\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max(src_len)-L)), 0) for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max(tgt_len)-L)), 0) for L in tgt_len])\n",
    "\n",
    "# 构造word embedding 第0行：padding的embedding\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "src_embedding = src_embedding_table(src_seq) \n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "\n",
    "# 构造position embedding\n",
    "pos_mat = torch.arange(max_position_len).reshape((-1, 1))\n",
    "i_mat = torch.pow(10000, torch.arange(0, model_dim, 2).reshape((1, -1))/model_dim)\n",
    "pe_embedding_table = torch.zeros((max_position_len, model_dim))\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat / i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat / i_mat)\n",
    "\n",
    "# 构造位置embedding\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "\n",
    "# 生成位置索引\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)), 0) for _ in src_len]).to(torch.int32) \n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)), 0) for _ in tgt_len]).to(torch.int32)\n",
    "\n",
    "# 构造每个位置的位置embedding\n",
    "src_pe_embedding = pe_embedding(src_pos)  \n",
    "tgt_pe_embedding = pe_embedding(tgt_pos)\n",
    "\n",
    "# 构造encoder的self-attention mask，保证注意力不会分配给padding的部分\n",
    "# mask的shape：[batch_size, max_src_len, max_src_len]，值为1或-inf\n",
    "vaild_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len)-L)), 0) for L in src_len]), 2)\n",
    "vaild_encoder_pos_matrix = torch.bmm(vaild_encoder_pos, vaild_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1 - vaild_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "\n",
    "# 模拟encoder的self-attention score\n",
    "score = torch.rand((batch_size, max(src_len), max(src_len)))\n",
    "\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "\n",
    "print(src_len)\n",
    "print(score)\n",
    "print(masked_score)\n",
    "print(prob)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
