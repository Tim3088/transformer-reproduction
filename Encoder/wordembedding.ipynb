{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.4789, -0.1258, -0.2743, -1.8418, -2.1465,  2.4762,  0.3513,  0.6852],\n",
      "        [ 1.5744, -1.4091, -0.6946,  1.5790,  1.0959, -0.7603,  0.6118,  1.0831],\n",
      "        [-1.2535,  0.0342,  0.8513, -0.0171, -0.3942,  0.2898, -0.7263, -0.6373],\n",
      "        [-0.7008,  1.4492, -0.2514, -1.3008, -1.5216, -0.2157, -0.2242,  0.4200],\n",
      "        [ 2.2568, -0.3080, -0.0466,  0.4633, -0.9516, -0.2778, -1.3498, -1.2884],\n",
      "        [-0.3184,  0.9886,  0.9204, -2.5826, -0.7704, -1.4521,  0.0217,  1.2625],\n",
      "        [ 1.0596,  2.2700, -0.5311,  0.3357,  0.6043,  0.8335,  0.3125, -0.3519],\n",
      "        [ 0.1616, -0.1158,  0.9844,  1.2782, -0.7955,  0.5378,  0.7150, -0.5199],\n",
      "        [-0.1703, -0.3390,  1.4381,  0.3746, -1.1038, -0.5669,  0.4854, -0.3689]],\n",
      "       requires_grad=True)\n",
      "tensor([[4, 5, 0, 0, 0],\n",
      "        [6, 3, 1, 7, 0]])\n",
      "tensor([[[ 2.2568, -0.3080, -0.0466,  0.4633, -0.9516, -0.2778, -1.3498,\n",
      "          -1.2884],\n",
      "         [-0.3184,  0.9886,  0.9204, -2.5826, -0.7704, -1.4521,  0.0217,\n",
      "           1.2625],\n",
      "         [ 1.4789, -0.1258, -0.2743, -1.8418, -2.1465,  2.4762,  0.3513,\n",
      "           0.6852],\n",
      "         [ 1.4789, -0.1258, -0.2743, -1.8418, -2.1465,  2.4762,  0.3513,\n",
      "           0.6852],\n",
      "         [ 1.4789, -0.1258, -0.2743, -1.8418, -2.1465,  2.4762,  0.3513,\n",
      "           0.6852]],\n",
      "\n",
      "        [[ 1.0596,  2.2700, -0.5311,  0.3357,  0.6043,  0.8335,  0.3125,\n",
      "          -0.3519],\n",
      "         [-0.7008,  1.4492, -0.2514, -1.3008, -1.5216, -0.2157, -0.2242,\n",
      "           0.4200],\n",
      "         [ 1.5744, -1.4091, -0.6946,  1.5790,  1.0959, -0.7603,  0.6118,\n",
      "           1.0831],\n",
      "         [ 0.1616, -0.1158,  0.9844,  1.2782, -0.7955,  0.5378,  0.7150,\n",
      "          -0.5199],\n",
      "         [ 1.4789, -0.1258, -0.2743, -1.8418, -2.1465,  2.4762,  0.3513,\n",
      "           0.6852]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# wordembedding 以序列建模为例\n",
    "batch_size = 2\n",
    "\n",
    "# 单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "\n",
    "# 序列的最大长度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)  # 源序列长度\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)  # 目标序列长度\n",
    "\n",
    "# 以单词索引构成的源句子和目标句子，构建batch，并且做了padding，默认值为0\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max_src_seq_len-L)), 0) for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max_tgt_seq_len-L)), 0) for L in tgt_len])\n",
    "\n",
    "# 构造word embedding 第零行为padding的embedding\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "src_embedding = src_embedding_table(src_seq) \n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "\n",
    "print(src_embedding_table.weight)\n",
    "print(src_seq)\n",
    "print(src_embedding)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
